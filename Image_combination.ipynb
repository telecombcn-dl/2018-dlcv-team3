{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility function to read images and turn them into a Pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadim(path):\n",
    "    im = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    im = np.array([im[:, :, 2], im[:, :, 1], im[:, :, 0]])\n",
    "    im = torch.from_numpy(im)\n",
    "    im = im.type('torch.FloatTensor')\n",
    "    im = im/128 - 2\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model we will use to extract features, in this case, VGG11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg11 = models.vgg11(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block, we define a series of architectures derived from VGG11, that we will use to extract different level features. It is known that higher layers extract higher level features. We only used the convoutional layers of the VGG for this experiment. We didn't use the dense layers output features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16_conv7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16_conv7, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # stop at conv7\n",
    "            *list(vgg11.features.children())[:-3]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "class VGG16_conv6(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16_conv6, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # stop at conv6\n",
    "            *list(vgg11.features.children())[:-5]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "class VGG16_conv5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16_conv5, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # stop at conv5\n",
    "            *list(vgg11.features.children())[:-8]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "class VGG16_conv4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16_conv4, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # stop at conv4\n",
    "            *list(vgg11.features.children())[:-10]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "class VGG16_conv3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16_conv3, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # stop at conv3\n",
    "            *list(vgg11.features.children())[:-13]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "class VGG16_conv2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16_conv2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # stop at conv2\n",
    "            *list(vgg11.features.children())[:-15]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "class VGG16_conv1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16_conv1, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # stop at conv1\n",
    "            *list(vgg11.features.children())[:-18]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "    \n",
    "# Just realized I forgot the 8th layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we compute the features we want our output image to have. For instance, low level features similar to the style image and higher level features similar to the content image. The features we're going to use are, respectively, the lower layers activations and higher layers activations.\n",
    "\n",
    "After that, we will optimize the pixels of a new image in order for them to have similar activations to the ones desired. \n",
    "\n",
    "To do that, the first thing we need to do is initialize the new image. Some options would be the style image, the content image or even a random initialization of the pixels. To do our first experiments, we chose to have as an initialization the content image.\n",
    "\n",
    "To find the opitmal parameters, we define a loss function which is the MSE between the desired features and the ones we actually have, for all the layers.\n",
    "\n",
    "Then, we will use the SGD technique to find the parameters (in this case, input image pixel values) that minimize this function.\n",
    "\n",
    "To calculate the gradient of the loss with respect to the pixel values, we backpropagate the error from each layer down to the pixel values, then we update the pixel values. We will repeat this for a few iterations, saving the result in each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    vgg1 = VGG16_conv1()\n",
    "    vgg2 = VGG16_conv2()\n",
    "    vgg3 = VGG16_conv3()\n",
    "    vgg4 = VGG16_conv4()\n",
    "    vgg5 = VGG16_conv5()\n",
    "    vgg6 = VGG16_conv6()\n",
    "    vgg7 = VGG16_conv7()\n",
    "\n",
    "    cont_im = loadim('landscape-small.png')\n",
    "\n",
    "    cont_im = cont_im.unsqueeze(0)\n",
    "\n",
    "    cont_im.requires_grad = True\n",
    "\n",
    "    style_im = loadim('van-gogh-small.png')\n",
    "    style_im = style_im.unsqueeze(0)\n",
    "\n",
    "    opt = optim.SGD([cont_im], lr=0.0001)\n",
    "\n",
    "    y1_targ = vgg1(style_im)\n",
    "    y2_targ = vgg2(style_im)\n",
    "    y3_targ = vgg3(style_im)\n",
    "    y4_targ = vgg4(style_im)\n",
    "    y5_targ = vgg5(style_im)\n",
    "    y6_targ = vgg6(style_im)\n",
    "    y7_targ = vgg7(style_im)\n",
    "    \n",
    "    input_im = cont_im\n",
    "\n",
    "    for i in range(20):\n",
    "\n",
    "        print('Iteration', i)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        y1_ = vgg1(input_im)\n",
    "        y2_ = vgg2(input_im)\n",
    "        y3_ = vgg3(input_im)\n",
    "        y4_ = vgg4(input_im)\n",
    "        y5_ = vgg5(input_im)\n",
    "        y6_ = vgg6(input_im)\n",
    "        y7_ = vgg7(input_im)\n",
    "\n",
    "        y1_d = y1_targ - y1_\n",
    "        y2_d = y2_targ - y2_\n",
    "        y3_d = y3_targ - y3_\n",
    "        y4_d = y4_targ - y4_\n",
    "        y5_d = y5_targ - y5_\n",
    "        y6_d = y6_targ - y6_\n",
    "        y7_d = y7_targ - y7_\n",
    "\n",
    "        y1_d = y1_d * y1_d\n",
    "        y2_d = y2_d * y2_d\n",
    "        y3_d = y3_d * y3_d\n",
    "        y4_d = y4_d * y4_d\n",
    "        y5_d = y5_d * y5_d\n",
    "        y6_d = y6_d * y6_d\n",
    "        y7_d = y7_d * y7_d\n",
    "\n",
    "        loss = torch.tensor(0, dtype=torch.float)\n",
    "        loss.requires_grad = True\n",
    "        for dif in [y1_d, y2_d, y3_d, y4_d, y5_d, y6_d, y7_d]:\n",
    "            l = torch.sum(dif)\n",
    "            loss = loss + l\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "        opt.step()\n",
    "\n",
    "        b = cont_im[0].detach().numpy()\n",
    "\n",
    "        b = np.rollaxis(b, 0, 3)\n",
    "\n",
    "        scipy.misc.imsave('content' + str(i) + '.jpg', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benet/Documents/virtualenv/DL/lib/python3.6/site-packages/ipykernel_launcher.py:74: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the resulting images is:\n",
    "![title](1234/content7.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
